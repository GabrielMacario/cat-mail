{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789ce30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pip\n",
    "\n",
    "!pip -q install gspread google-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc8f11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc940740",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FILTERS_FILE = \"filters.json\"\n",
    "\n",
    "DEFAULT_FILTERS = {\n",
    "    \"imap_search\": \"ALL\",\n",
    "    \"include\": {\n",
    "        \"from_contains\": [],\n",
    "        \"subject_contains\": [],\n",
    "        \"body_contains\": []\n",
    "    },\n",
    "    \"exclude\": {\n",
    "        \"from_contains\": [],\n",
    "        \"subject_contains\": [],\n",
    "        \"body_contains\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_filters():\n",
    "    if not os.path.exists(FILTERS_FILE):\n",
    "        return DEFAULT_FILTERS\n",
    "\n",
    "    with open(FILTERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    # merge simples (garante chaves)\n",
    "    out = DEFAULT_FILTERS.copy()\n",
    "    out[\"imap_search\"] = cfg.get(\"imap_search\", out[\"imap_search\"])\n",
    "\n",
    "    out[\"include\"] = out[\"include\"].copy()\n",
    "    out[\"include\"][\"from_contains\"] = cfg.get(\"include\", {}).get(\"from_contains\", [])\n",
    "    out[\"include\"][\"subject_contains\"] = cfg.get(\"include\", {}).get(\"subject_contains\", [])\n",
    "\n",
    "    out[\"exclude\"] = out[\"exclude\"].copy()\n",
    "    out[\"exclude\"][\"from_contains\"] = cfg.get(\"exclude\", {}).get(\"from_contains\", [])\n",
    "    out[\"exclude\"][\"subject_contains\"] = cfg.get(\"exclude\", {}).get(\"subject_contains\", [])\n",
    "    out[\"include\"][\"body_contains\"] = cfg.get(\"include\", {}).get(\"body_contains\", [])\n",
    "    out[\"exclude\"][\"body_contains\"] = cfg.get(\"exclude\", {}).get(\"body_contains\", [])\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "def contains_any(text: str, needles) -> bool:\n",
    "    text_low = (text or \"\").lower()\n",
    "    return any((n or \"\").lower() in text_low for n in needles)\n",
    "\n",
    "def passes_filters(subject: str, from_header: str, body: str, filters: dict) -> bool:\n",
    "    inc = filters.get(\"include\", {})\n",
    "    exc = filters.get(\"exclude\", {})\n",
    "\n",
    "    # INCLUDE\n",
    "    if inc.get(\"from_contains\") and not contains_any(from_header, inc[\"from_contains\"]):\n",
    "        return False\n",
    "\n",
    "    if inc.get(\"subject_contains\") and not contains_any(subject, inc[\"subject_contains\"]):\n",
    "        return False\n",
    "\n",
    "    if inc.get(\"body_contains\") and not contains_any(body, inc[\"body_contains\"]):\n",
    "        return False\n",
    "\n",
    "    # EXCLUDE\n",
    "    if exc.get(\"from_contains\") and contains_any(from_header, exc[\"from_contains\"]):\n",
    "        return False\n",
    "\n",
    "    if exc.get(\"subject_contains\") and contains_any(subject, exc[\"subject_contains\"]):\n",
    "        return False\n",
    "\n",
    "    if exc.get(\"body_contains\") and contains_any(body, exc[\"body_contains\"]):\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373394f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import socket\n",
    "from datetime import datetime\n",
    "\n",
    "import gspread\n",
    "from google.auth import default\n",
    "\n",
    "IMAP_HOST = \"imap.gmail.com\"\n",
    "IMAP_PORT = 993\n",
    "\n",
    "STATE_FILE = \"state.json\"\n",
    "CSV_FILE = \"emails.csv\"\n",
    "CSV_HEADERS = [\"id\", \"subject\", \"body\"]\n",
    "\n",
    "FILTERS_FILE = \"filters.json\"\n",
    "\n",
    "# ====== Robustez ======\n",
    "SOCKET_TIMEOUT_SECONDS = 45\n",
    "IMAP_FETCH_RETRIES = 3\n",
    "IMAP_RETRY_SLEEP_SECONDS = 2\n",
    "MAX_EMAILS_PER_RUN = 50\n",
    "ONLY_HEADERS = False\n",
    "TRUNCATE_BODY_CHARS = 20000  # pode aumentar depois\n",
    "\n",
    "# ====== Google Sheets config ======\n",
    "ENABLE_SHEETS = True\n",
    "SPREADSHEET_ID = \"1PhL-0EjUfy6UlKHh0PeKdQ8Mi-yKqGBllT637pi1C2c\"\n",
    "WORKSHEET_NAME = \"emails\"\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "\n",
    "# ---------- Filters ----------\n",
    "DEFAULT_FILTERS = {\n",
    "    \"imap_search\": \"ALL\",\n",
    "    \"include\": {\n",
    "        \"from_contains\": [],\n",
    "        \"subject_contains\": [],\n",
    "        \"body_contains\": [],\n",
    "    },\n",
    "    \"exclude\": {\n",
    "        \"from_contains\": [],\n",
    "        \"subject_contains\": [],\n",
    "        \"body_contains\": [],\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def load_filters():\n",
    "    if not os.path.exists(FILTERS_FILE):\n",
    "        return DEFAULT_FILTERS\n",
    "\n",
    "    with open(FILTERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    out = {\n",
    "        \"imap_search\": cfg.get(\"imap_search\", DEFAULT_FILTERS[\"imap_search\"]),\n",
    "        \"include\": {\n",
    "            \"from_contains\": cfg.get(\"include\", {}).get(\"from_contains\", []),\n",
    "            \"subject_contains\": cfg.get(\"include\", {}).get(\"subject_contains\", []),\n",
    "            \"body_contains\": cfg.get(\"include\", {}).get(\"body_contains\", []),\n",
    "        },\n",
    "        \"exclude\": {\n",
    "            \"from_contains\": cfg.get(\"exclude\", {}).get(\"from_contains\", []),\n",
    "            \"subject_contains\": cfg.get(\"exclude\", {}).get(\"subject_contains\", []),\n",
    "            \"body_contains\": cfg.get(\"exclude\", {}).get(\"body_contains\", []),\n",
    "        }\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def contains_any(text: str, needles) -> bool:\n",
    "    text_low = (text or \"\").lower()\n",
    "    return any((n or \"\").lower() in text_low for n in needles)\n",
    "\n",
    "\n",
    "def passes_filters(subject: str, from_header: str, body: str, filters: dict) -> bool:\n",
    "    inc = filters.get(\"include\", {})\n",
    "    exc = filters.get(\"exclude\", {})\n",
    "\n",
    "    # INCLUDE (AND)\n",
    "    if inc.get(\"from_contains\") and not contains_any(from_header, inc[\"from_contains\"]):\n",
    "        return False\n",
    "    if inc.get(\"subject_contains\") and not contains_any(subject, inc[\"subject_contains\"]):\n",
    "        return False\n",
    "    if inc.get(\"body_contains\") and not contains_any(body, inc[\"body_contains\"]):\n",
    "        return False\n",
    "\n",
    "    # EXCLUDE (OR)\n",
    "    if exc.get(\"from_contains\") and contains_any(from_header, exc[\"from_contains\"]):\n",
    "        return False\n",
    "    if exc.get(\"subject_contains\") and contains_any(subject, exc[\"subject_contains\"]):\n",
    "        return False\n",
    "    if exc.get(\"body_contains\") and contains_any(body, exc[\"body_contains\"]):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# ---------- State ----------\n",
    "def load_state():\n",
    "    if os.path.exists(STATE_FILE):\n",
    "        with open(STATE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"last_uid\": 0}\n",
    "\n",
    "\n",
    "def save_state(state):\n",
    "    with open(STATE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# ---------- Decoding ----------\n",
    "def safe_decode_bytes(payload: bytes, charset: str) -> str:\n",
    "    charset = (charset or \"utf-8\").strip().lower()\n",
    "    if charset in (\"unknown-8bit\", \"x-unknown\", \"unknown\"):\n",
    "        charset = \"utf-8\"\n",
    "    try:\n",
    "        return payload.decode(charset, errors=\"replace\")\n",
    "    except LookupError:\n",
    "        return payload.decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "\n",
    "def decode_mime_words(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    parts = decode_header(s)\n",
    "    out = []\n",
    "    for text, enc in parts:\n",
    "        if isinstance(text, bytes):\n",
    "            enc = (enc or \"utf-8\").strip().lower()\n",
    "            if enc in (\"unknown-8bit\", \"x-unknown\", \"unknown\"):\n",
    "                enc = \"utf-8\"\n",
    "            try:\n",
    "                out.append(text.decode(enc, errors=\"replace\"))\n",
    "            except LookupError:\n",
    "                out.append(text.decode(\"utf-8\", errors=\"replace\"))\n",
    "        else:\n",
    "            out.append(text)\n",
    "    return \"\".join(out)\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip()\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    if len(s) > TRUNCATE_BODY_CHARS:\n",
    "        s = s[:TRUNCATE_BODY_CHARS] + \" ...[truncado]\"\n",
    "    return s\n",
    "\n",
    "\n",
    "def extract_body(msg):\n",
    "    text_plain = None\n",
    "    text_html = None\n",
    "\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            ctype = part.get_content_type()\n",
    "            disp = str(part.get(\"Content-Disposition\") or \"\")\n",
    "            if \"attachment\" in disp.lower():\n",
    "                continue\n",
    "\n",
    "            payload = part.get_payload(decode=True)\n",
    "            if not payload:\n",
    "                continue\n",
    "\n",
    "            charset = part.get_content_charset() or \"utf-8\"\n",
    "            content = safe_decode_bytes(payload, charset)\n",
    "\n",
    "            if ctype == \"text/plain\" and text_plain is None:\n",
    "                text_plain = content\n",
    "            elif ctype == \"text/html\" and text_html is None:\n",
    "                text_html = content\n",
    "    else:\n",
    "        ctype = msg.get_content_type()\n",
    "        payload = msg.get_payload(decode=True) or b\"\"\n",
    "        charset = msg.get_content_charset() or \"utf-8\"\n",
    "        content = safe_decode_bytes(payload, charset)\n",
    "\n",
    "        if ctype == \"text/plain\":\n",
    "            text_plain = content\n",
    "        elif ctype == \"text/html\":\n",
    "            text_html = content\n",
    "\n",
    "    if text_plain:\n",
    "        return clean_text(text_plain)\n",
    "\n",
    "    if text_html:\n",
    "        no_script = re.sub(r\"<(script|style)[^>]*>.*?</\\1>\", \"\", text_html, flags=re.S | re.I)\n",
    "        no_tags = re.sub(r\"<[^>]+>\", \" \", no_script)\n",
    "        no_tags = re.sub(r\"\\s+\", \" \", no_tags).strip()\n",
    "        return clean_text(no_tags)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ---------- CSV ----------\n",
    "def ensure_csv_headers():\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        with open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(CSV_HEADERS)\n",
    "        log(f\"CSV criado com cabeçalho: {CSV_FILE}\")\n",
    "\n",
    "\n",
    "def append_rows_csv(rows):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(CSV_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)\n",
    "    log(f\"CSV: escreveu {len(rows)} linhas.\")\n",
    "\n",
    "\n",
    "# ---------- IMAP fetch retry ----------\n",
    "def imap_uid_fetch_with_retry(mail, uid_b: bytes, what: str):\n",
    "    last_err = None\n",
    "    for attempt in range(1, IMAP_FETCH_RETRIES + 1):\n",
    "        try:\n",
    "            status, msg_data = mail.uid(\"fetch\", uid_b, what)\n",
    "            if status == \"OK\" and msg_data and msg_data[0]:\n",
    "                return status, msg_data\n",
    "            last_err = (status, msg_data)\n",
    "        except (imaplib.IMAP4.abort, imaplib.IMAP4.error, socket.timeout) as e:\n",
    "            last_err = e\n",
    "            log(f\"⚠️ fetch falhou (tentativa {attempt}/{IMAP_FETCH_RETRIES}) uid={uid_b!r}: {e}\")\n",
    "            time.sleep(IMAP_RETRY_SLEEP_SECONDS)\n",
    "    raise RuntimeError(f\"Falha ao buscar mensagem (uid={uid_b!r}). Último erro: {last_err}\")\n",
    "\n",
    "\n",
    "# ---------- Sheets ----------\n",
    "def connect_sheets_oauth_colab(spreadsheet_id: str, worksheet_name: str):\n",
    "    creds, _ = default()\n",
    "    gc = gspread.authorize(creds)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "\n",
    "    try:\n",
    "        ws = sh.worksheet(worksheet_name)\n",
    "    except gspread.WorksheetNotFound:\n",
    "        ws = sh.add_worksheet(title=worksheet_name, rows=2000, cols=10)\n",
    "\n",
    "    ws.update(values=[CSV_HEADERS], range_name=\"A1:C1\")\n",
    "    return ws\n",
    "\n",
    "\n",
    "def main():\n",
    "    filters = load_filters()\n",
    "    log(f\"Filtros carregados: imap_search={filters['imap_search']}\")\n",
    "\n",
    "    # Credenciais IMAP (hardcoded, com opção env)\n",
    "    GMAIL_USER = os.environ.get(\"GMAIL_USER\") or \"seuemail@gmail.com\"\n",
    "    GMAIL_PASS = os.environ.get(\"GMAIL_PASS\") or \"SUA_SENHA_DE_APP\"\n",
    "\n",
    "    GMAIL_PASS = GMAIL_PASS.replace(\" \", \"\")\n",
    "\n",
    "    socket.setdefaulttimeout(SOCKET_TIMEOUT_SECONDS)\n",
    "\n",
    "    log(\"Iniciando...\")\n",
    "    state = load_state()\n",
    "    last_uid = int(state.get(\"last_uid\", 0))\n",
    "    log(f\"Checkpoint atual (last_uid): {last_uid}\")\n",
    "\n",
    "    ensure_csv_headers()\n",
    "\n",
    "    ws = None\n",
    "    if ENABLE_SHEETS:\n",
    "        try:\n",
    "            log(\"Conectando no Google Sheets (OAuth do Colab)...\")\n",
    "            ws = connect_sheets_oauth_colab(SPREADSHEET_ID, WORKSHEET_NAME)\n",
    "            log(\"Sheets conectado ✅\")\n",
    "        except Exception as e:\n",
    "            log(f\"⚠️ Falha ao conectar no Sheets ({e}). Vou salvar só no CSV.\")\n",
    "            ws = None\n",
    "\n",
    "    # IMAP\n",
    "    log(\"Conectando no IMAP...\")\n",
    "    mail = imaplib.IMAP4_SSL(IMAP_HOST, IMAP_PORT)\n",
    "    log(\"Fazendo login...\")\n",
    "    mail.login(GMAIL_USER, GMAIL_PASS)\n",
    "\n",
    "    log(\"Selecionando INBOX...\")\n",
    "    mail.select(\"INBOX\")\n",
    "\n",
    "    start = last_uid + 1\n",
    "    imap_search = filters.get(\"imap_search\", \"ALL\").strip() or \"ALL\"\n",
    "\n",
    "    log(f\"Buscando UIDs a partir de {start} com filtro IMAP: {imap_search}\")\n",
    "    # aplicando UNSEEN/ALL/SINCE etc no servidor\n",
    "    status, data = mail.uid(\"search\", None, f\"(UID {start}:* {imap_search})\")\n",
    "    if status != \"OK\":\n",
    "        mail.logout()\n",
    "        raise RuntimeError(f\"Falha ao buscar emails via IMAP: status={status}, data={data}\")\n",
    "\n",
    "    uids = data[0].split()\n",
    "    total = len(uids)\n",
    "    log(f\"Encontrados {total} emails candidatos (UID >= {start} + {imap_search}).\")\n",
    "\n",
    "    if not uids:\n",
    "        log(\"Nenhum email novo. Finalizando.\")\n",
    "        mail.logout()\n",
    "        return\n",
    "\n",
    "    if total > MAX_EMAILS_PER_RUN:\n",
    "        log(f\"⚠️ Limitando processamento a {MAX_EMAILS_PER_RUN} emails nesta execução.\")\n",
    "        uids = uids[:MAX_EMAILS_PER_RUN]\n",
    "\n",
    "    rows = []\n",
    "    max_uid = last_uid\n",
    "\n",
    "    for i, uid_b in enumerate(uids, start=1):\n",
    "        uid = int(uid_b.decode(\"utf-8\"))\n",
    "        log(f\"[{i}/{len(uids)}] Processando UID {uid}...\")\n",
    "\n",
    "        # header (subject/from)\n",
    "        _, msg_data = imap_uid_fetch_with_retry(mail, uid_b, \"(BODY.PEEK[HEADER])\")\n",
    "        raw_header = msg_data[0][1]\n",
    "        msg_header = email.message_from_bytes(raw_header)\n",
    "        subject = decode_mime_words(msg_header.get(\"Subject\", \"\"))\n",
    "        from_header = decode_mime_words(msg_header.get(\"From\", \"\"))\n",
    "\n",
    "        # body (precisa pro filtro body_contains)\n",
    "        _, msg_data = imap_uid_fetch_with_retry(mail, uid_b, \"(RFC822)\")\n",
    "        raw = msg_data[0][1]\n",
    "        msg_full = email.message_from_bytes(raw)\n",
    "        body = extract_body(msg_full)\n",
    "\n",
    "        if not passes_filters(subject, from_header, body, filters):\n",
    "            log(f\"Pulando UID {uid} (não bateu nos filtros)\")\n",
    "            continue\n",
    "\n",
    "        rows.append([str(uid), subject, body])\n",
    "        if uid > max_uid:\n",
    "            max_uid = uid\n",
    "\n",
    "    mail.logout()\n",
    "\n",
    "    append_rows_csv(rows)\n",
    "\n",
    "    if ws is not None and rows:\n",
    "        ws.append_rows(rows, value_input_option=\"RAW\")\n",
    "        log(f\"Sheets: adicionadas {len(rows)} linhas ✅\")\n",
    "    else:\n",
    "        log(\"Sheets: nada pra adicionar nesta execução (ou não conectado).\")\n",
    "\n",
    "    state[\"last_uid\"] = max_uid\n",
    "    state[\"last_run\"] = {\n",
    "        \"processed\": len(rows),\n",
    "        \"max_uid\": max_uid,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"only_headers\": ONLY_HEADERS,\n",
    "        \"sheets_connected\": ws is not None,\n",
    "        \"imap_search\": imap_search,\n",
    "    }\n",
    "    save_state(state)\n",
    "\n",
    "    log(f\"✅ Concluído. Gravados {len(rows)} emails filtrados. Novo checkpoint UID: {max_uid}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
